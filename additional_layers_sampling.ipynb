{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "080784ea",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6a8aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "\n",
    "import emcee\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gs\n",
    "from matplotlib import font_manager\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import ListedColormap\n",
    "from cycler import cycler\n",
    "import corner\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import lymph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad80910",
   "metadata": {},
   "source": [
    "## Creating or Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fd5cb54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unilateral lymphatic system with 1 tumor(s) and 6 LNL(s).\n",
      "primary-0.0%->II primary-0.0%->III primary-0.0%->IV primary-0.0%->VII II-0.0%->I II-0.0%->III II-0.0%->V II-0.0%->VII III-0.0%->IV\n"
     ]
    }
   ],
   "source": [
    "NEW_MODEL = True\n",
    "\n",
    "filename = \"latest_extended.hdf5\"\n",
    "\n",
    "if not NEW_MODEL:\n",
    "    extended_systm = lymph.utils.system_from_hdf(\n",
    "    filename=filename,\n",
    "    name=\"extended/model\")\n",
    "else:\n",
    "    graph = {\n",
    "        ('tumor', 'primary') : ['II', 'III', 'IV','VII'],\n",
    "        ('lnl', 'I')         : [], \n",
    "        ('lnl', 'II')        : ['I', 'III', 'V', 'VII'], \n",
    "        ('lnl', 'III')       : ['IV'], \n",
    "        ('lnl', 'IV')        : [],\n",
    "        ('lnl', 'V')         : [],\n",
    "        ('lnl', 'VII')       : [],\n",
    "    }\n",
    "    extended_systm = lymph.Unilateral(graph=graph)\n",
    "\n",
    "print(extended_systm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac794b",
   "metadata": {},
   "source": [
    "## Modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2663e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NEW_MODEL:\n",
    "    spsn = {\"PET\": [0.86, 0.79],\n",
    "            \"MRI\": [0.63, 0.81],\n",
    "            \"diagnostic_consensus\": [0.63, 0.81],\n",
    "            \"pathology\": [1., 1.]}\n",
    "#                         ^   ^\n",
    "#                specificty   sensitivity\n",
    "extended_systm.modalities = spsn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bd5c6f",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97c60b4",
   "metadata": {},
   "source": [
    "#### Method to determine the involvement of a layer in a single patient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5053b300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def layer_involvement_expectation(inv: Optional[int], spsns: List[tuple])-> int:\n",
    "    \"\"\"Determine which layers are involved given the different (conflicting) measurements:\n",
    "\n",
    "        Args:\n",
    "            inv:    For one single layer, one entry gives the measured involvement for the\n",
    "                    respective modality\n",
    "            spsns:  Each entry of the list is the spsn tuple of the respective modality\n",
    "\n",
    "    \"\"\"\n",
    "    no_of_measurements = 0\n",
    "    prob = 0\n",
    "    for i , spsn in enumerate(spsns):\n",
    "        if(inv[i] == True):\n",
    "            no_of_measurements+=1\n",
    "            prob += spsn[1]\n",
    "        elif(inv[i] == False):\n",
    "            no_of_measurements+=1\n",
    "            prob += (1-spsn[0])\n",
    "    if(no_of_measurements == 0):\n",
    "        return 0\n",
    "    mean_prob = prob / no_of_measurements\n",
    "    if(mean_prob >= 0.5):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def layer_involvement_statistical(inv: Optional[int], spsns: List[tuple])-> int:\n",
    "    \"\"\"Determine which layers are involved given the different (conflicting) measurements:\n",
    "\n",
    "        Args:\n",
    "            inv:    For one single layer, one entry gives the measured involvement for the\n",
    "                    respective modality\n",
    "            spsns:  Each entry of the list is the spsn tuple of the respective modality\n",
    "\n",
    "    \"\"\"\n",
    "    p_healthy = 1\n",
    "    p_involved = 1\n",
    "    for i , spsn in enumerate(spsns):\n",
    "        if(inv[i] == True):\n",
    "            p_healthy *= 1-spsn[1]\n",
    "            p_involved *= spsn[1]\n",
    "        elif(inv[i] == False):\n",
    "            p_healthy *= spsn[0]\n",
    "            p_involved *= 1-spsn[0]\n",
    "    if(p_healthy < p_involved):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def layer_involvement_hierarchical(inv: Optional[int], spsns: List[tuple])-> int:\n",
    "    \"\"\"Determine which layers are involved given the different (conflicting) measurements:\n",
    "       hierarchy: 1.Pathology,  2.Diagnostic consensus,  3. PET/CT,  4.MRI\n",
    "\n",
    "        Args:\n",
    "            inv:    For one single layer, one entry gives the measured involvement for the\n",
    "                    respective modality. For this function the modalities have to be given in the hierachical\n",
    "                    order -> pathology first etc.\n",
    "            spsns:  Each entry of the list is the spsn tuple of the respective modality\n",
    "\n",
    "    \"\"\"\n",
    "    spsns_with_index = []\n",
    "    for i, spsn in enumerate(spsns):\n",
    "        spsn_w_i = list(spsn)\n",
    "        spsn_w_i.append(i)\n",
    "        spsns_with_index.append(tuple(spsn_w_i))\n",
    "    zipped_list = zip(spsns, inv)\n",
    "    sorted_by_sp = sorted(zipped_list, key=lambda x: x[0], reverse=True)\n",
    "    sorted_by_sn = sorted(zipped_list, key=lambda x: x[1], reverse=True)\n",
    "    inv_by_sp = [element for _, element in sorted_by_sp]\n",
    "    inv_by_sn = [element for _, element in sorted_by_sn]\n",
    "    for i, invol in inv_by_sp:\n",
    "        if(inv_by_sp[i] is not None):\n",
    "            if(inv_by_sp[i] == inv_by_sn[i]):\n",
    "                return inv_by_sp[i]\n",
    "        else:\n",
    "            \n",
    "            pass\n",
    "    return 0\n",
    "\n",
    "#print(layer_involvement_hierarchical([0, 0, 1, 0], [(1.,1.), (0.63, 0.81), (0.86, 0.79), (0.63, 0.81)]))\n",
    "\n",
    "\n",
    "# all_possible_measurements = list(itertools.product([0,1,None], repeat=4))\n",
    "# for meas in all_possible_measurements:\n",
    "#     exp = layer_involvement_expectation(meas, [(1.,1.), (0.63, 0.81), (0.86, 0.79), (0.63, 0.81)])\n",
    "#     stat = layer_involvement_statistical(meas, [(1.,1.), (0.63, 0.81), (0.86, 0.79), (0.63, 0.81)])\n",
    "#     hier = layer_involvement_hierarchical(meas, [(1.,1.), (0.63, 0.81), (0.86, 0.79), (0.63, 0.81)])\n",
    "#     if(exp != stat):\n",
    "#         print(meas, f\"\\t\\t\\t\\texp={exp}   !=   stat={stat}\")\n",
    "#     if(hier != stat):\n",
    "#         print(meas, f\"\\t\\t\\t\\thier={hier}   !=   stat={stat}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bba549d",
   "metadata": {},
   "source": [
    "### Method to count the occurrences of involved layers in the real Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9c21062",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Luca\\AppData\\Local\\Temp\\ipykernel_13432\\3353186479.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ipsi_data[\"info\",\"t_stage\"]= t_stage\n"
     ]
    }
   ],
   "source": [
    "if NEW_MODEL:\n",
    "    data = pd.read_csv(\"latest.csv\", header=[0,1,2] )\n",
    "    t_stage = data.iloc[:,18]\n",
    "    data = data.iloc[:,21:168]\n",
    "    ipsi_data = data.xs(\"ipsi\",level=1,axis=1)\n",
    "    t_stage.loc[t_stage <= 2, ] = \"early\"\n",
    "    t_stage.loc[t_stage!=\"early\", ] = \"late\"\n",
    "    \n",
    "    \n",
    "    ipsi_data[\"info\",\"t_stage\"]= t_stage\n",
    "    ipsi_data = ipsi_data.drop(['Ia', 'Ib',\"IIa\",\"IIb\"], level=1, axis=1)\n",
    "    ipsi_data = ipsi_data.drop(['CT', 'FNA',\"pCT\"], level=0, axis=1)\n",
    "\n",
    "    extended_systm.patient_data = ipsi_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e3d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_occurence(df, t_stage=True):\n",
    "    #All labels of the Columns\n",
    "    layer_cols = df.columns.get_level_values(1)\n",
    "\n",
    "    #Delete Duplicates and t-stage from list\n",
    "    layers = list(dict.fromkeys(layer_cols))\n",
    "    if(t_stage == True):\n",
    "        layers = layers[:-1]\n",
    "   \n",
    "    #Create Empty DataFrame to store the occurrences\n",
    "    occurr_table = pd.DataFrame(np.zeros((1, len(layers))), columns=layers)\n",
    "\n",
    "    #Fill the occurrence table\n",
    "    for layer in layers:\n",
    "        select = layer_cols.isin([layer])\n",
    "        level_data = df.loc[:, select]\n",
    "        for index, row in level_data.iterrows():\n",
    "            patient_occ = row.to_dict()\n",
    "            patient_occ2 = {key[0]: val for (key, val) in patient_occ.items()}\n",
    "            involved = patient_layer_involvement(patient_occ2)\n",
    "            if(involved):\n",
    "                occurr_table[layer] += 1\n",
    "    return occurr_table\n",
    "\n",
    "layer_occurence(ipsi_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bbd48d",
   "metadata": {},
   "source": [
    "#### Compare Dataset with Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e1c12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comparison_risk_w_dataset(df, layers, time_dists):\n",
    "\n",
    "    ##layers = [\"I\", \"IV\"]\n",
    "    \n",
    "    # time_dists={\n",
    "    #     \"early\": lymph.utils.fast_binomial_pmf(t, max_t, early_p),\n",
    "    #     \"late\" : lymph.utils.fast_binomial_pmf(t, max_t, mean_late_p)\n",
    "    # }\n",
    "    \n",
    "    all_layer_cols = df.columns.get_level_values(1)\n",
    "    all_layers = list(dict.fromkeys(all_layer_cols))[:-1]\n",
    "    involvement = np.repeat(None, len(all_layers))\n",
    "    for i, layer in enumerate(all_layers):\n",
    "        if(layers.includes(layer)):\n",
    "            involvement[i]= 1\n",
    "    diagnose = {\"PET\": [None,None,None,None,None,None]}\n",
    "    \n",
    "    for key in time_dists.keys():\n",
    "        risk =  extended_systm.risk(\n",
    "                        diagnoses=diagnose, inv=involvement,\n",
    "                        time_dist=time_dists[key], \n",
    "                        mode=\"HMM\"\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917ec258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc495797",
   "metadata": {},
   "source": [
    "## Storage of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9bbf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NEW_MODEL:\n",
    "    extended_systm.to_hdf(\n",
    "        filename=filename, \n",
    "        name=\"extended/model\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306350c3",
   "metadata": {},
   "source": [
    "## Likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc23bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings for the binom distributions\n",
    "early_p=0.3\n",
    "max_t=10\n",
    "t = np.arange(max_t + 1)\n",
    "\n",
    "def llh(theta):\n",
    "    spread_probs, late_p = theta[:-1], theta[-1]\n",
    "    \n",
    "    print(\"run\")\n",
    "    if late_p > 1. or late_p < 0.:\n",
    "        return -np.inf\n",
    "    \n",
    "    \n",
    "    time_dists={\n",
    "        \"early\": sp.stats.binom.pmf(t, max_t, early_p),\n",
    "        \"late\" : sp.stats.binom.pmf(t, max_t, late_p),\n",
    "    }\n",
    "     \n",
    "    return extended_systm.marginal_log_likelihood(spread_probs, t_stages=[\"early\", \"late\"], time_dists=time_dists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464512f4",
   "metadata": {},
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484f5ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for the sampler\n",
    "ndim = len(extended_systm.spread_probs) + 1\n",
    "nwalkers = 20 * ndim\n",
    "nstep = 10000\n",
    "burnin = 5000\n",
    "moves = [(emcee.moves.DEMove(), 0.8), (emcee.moves.DESnookerMove(), 0.2)]\n",
    "\n",
    "\n",
    "if NEW_MODEL:\n",
    "    #prepare the backend\n",
    "    backend = emcee.backends.HDFBackend(\n",
    "        filename=filename,\n",
    "        name=\"extended/samples\"\n",
    "    )\n",
    "    backend.reset(nwalkers, ndim)\n",
    "\n",
    "    \n",
    "    # starting point\n",
    "    initial_spread_probs = np.random.uniform(low=0., high=1., size=(nwalkers,ndim))\n",
    "\n",
    "    \n",
    "    if __name__ == \"__main__\":\n",
    "        with Pool() as pool:\n",
    "            sampler = emcee.EnsembleSampler(\n",
    "                nwalkers, ndim, \n",
    "                llh, \n",
    "                moves=moves, pool=pool,\n",
    "                backend=backend\n",
    "            )\n",
    "            sampler.run_mcmc(initial_spread_probs, nstep, progress=True)\n",
    "        samples_HMM = sampler.get_chain(flat=True, discard=burnin)\n",
    "        print(samples_HMM)      \n",
    "else:\n",
    "    recover_backend = emcee.backends.HDFBackend(filename=filename, name=\"extended/samples\")\n",
    "    samples_HMM = recover_backend.get_chain(flat=True, discard=burnin)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4934c6d2",
   "metadata": {},
   "source": [
    "## Separating the Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415b6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "spread_probs = []\n",
    "late_p = []\n",
    "for sample in samples_HMM:\n",
    "    spread_probs.append(sample[:-1])\n",
    "    late_p.append(sample[-1])\n",
    "\n",
    "extended_systm.spread_probs = np.mean(spread_probs, axis=0)\n",
    "mean_late_p = np.mean(np.array(late_p), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4696f5d7",
   "metadata": {},
   "source": [
    "## Plot Settings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74295274",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"lymph.mplstyle\")\n",
    "\n",
    "def set_size(width=\"single\", unit=\"cm\", ratio=\"golden\"):\n",
    "    if width == \"single\":\n",
    "        width = 10\n",
    "    elif width == \"full\":\n",
    "        width = 32\n",
    "    else:\n",
    "        try:\n",
    "            width = width\n",
    "        except:\n",
    "            width = 10\n",
    "\n",
    "    if unit == \"cm\":\n",
    "        width = width / 2.54\n",
    "\n",
    "    if ratio == \"golden\":\n",
    "        ratio = 1.618\n",
    "    else:\n",
    "        ratio = ratio\n",
    "\n",
    "    try:\n",
    "        height = width / ratio\n",
    "    except:\n",
    "        height = width / 1.618\n",
    "\n",
    "    return (width, height)\n",
    "\n",
    "labels = [r\"$\\tilde{b}_2$\", r\"$\\tilde{b}_3$\",\n",
    "          r\"$\\tilde{b}_4$\", r\"$\\tilde{b}_7$\",\n",
    "          r\"$\\tilde{t}_{21}$\", r\"$\\tilde{t}_{23}$\", r\"$\\tilde{t}_{25}$\", r\"$\\tilde{t}_{27}$\", r\"$\\tilde{t}_{36}$\"]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=set_size(width=\"full\", ratio=1))\n",
    "\n",
    "\n",
    "# USZ colors\n",
    "usz_blue = '#005ea8'\n",
    "usz_green = '#00afa5'\n",
    "usz_red = '#ae0060'\n",
    "usz_orange = '#f17900'\n",
    "usz_gray = '#c5d5db'\n",
    "\n",
    "# colormaps\n",
    "white_to_blue  = LinearSegmentedColormap.from_list(\"white_to_blue\", \n",
    "                                                   [\"#ffffff\", usz_blue], \n",
    "                                                   N=256)\n",
    "white_to_green = LinearSegmentedColormap.from_list(\"white_to_green\", \n",
    "                                                   [\"#ffffff\", usz_green], \n",
    "                                                   N=256)\n",
    "green_to_red   = LinearSegmentedColormap.from_list(\"green_to_red\", \n",
    "                                                   [usz_green, usz_red], \n",
    "                                                   N=256)\n",
    "\n",
    "h = usz_gray.lstrip('#')\n",
    "gray_rgba = tuple(int(h[i:i+2], 16) / 255. for i in (0, 2, 4)) + (1.0,)\n",
    "tmp = LinearSegmentedColormap.from_list(\"tmp\", [usz_green, usz_red], N=128)\n",
    "tmp = tmp(np.linspace(0., 1., 128))\n",
    "tmp = np.vstack([np.array([gray_rgba]*128), tmp])\n",
    "halfGray_halfGreenToRed = ListedColormap(tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07de43a7",
   "metadata": {},
   "source": [
    "## Corner Plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8222e898",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "corner.corner(np.array(spread_probs), labels=labels, smooth=True, fig=fig,\n",
    "              hist_kwargs={'histtype': 'stepfilled', 'color': usz_blue},\n",
    "              **{'plot_datapoints': False, 'no_fill_contours': True,\n",
    "                 \"density_cmap\": white_to_blue.reversed(),\n",
    "                 \"contour_kwargs\": {\"colors\": \"k\"},\n",
    "                 \"levels\": np.array([0.2, 0.5, 0.8])},\n",
    "              show_titles=True, title_kwargs={\"fontsize\": \"medium\"})\n",
    "\n",
    "axes = fig.get_axes()\n",
    "for ax in axes:\n",
    "    ax.grid(False)\n",
    "\n",
    "\n",
    "plt.savefig(\"corner_HMM.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(\"corner_HMM.svg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4391894",
   "metadata": {},
   "source": [
    "## Transition Matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a133c275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# modify the transition matrix for nicer coloring\n",
    "mod_A = -1 * np.ones_like(extended_systm.A)\n",
    "for key, nums in extended_systm.mask.items():\n",
    "    for i in nums:\n",
    "        mod_A[key, i] = extended_systm.A[key, i]\n",
    "\n",
    "# Divide the Matrix into three submatrices\n",
    "x_values = [extended_systm.state_list[:32],extended_systm.state_list[32:], extended_systm.state_list[32:]]\n",
    "y_values = [extended_systm.state_list[:32],extended_systm.state_list[:32], extended_systm.state_list[32:]]\n",
    "partA = [mod_A[:32,:32], mod_A[:32,32:], mod_A[32:,32:]]\n",
    "name = [\"1\", \"2\",\"3\"]\n",
    "\n",
    "#Create the plot for each submatrix\n",
    "for k , val in enumerate(x_values):\n",
    "    fig, ax = plt.subplots(figsize=set_size(ratio=1., width=\"full\"),\n",
    "                       constrained_layout=True)\n",
    "\n",
    "    h = ax.imshow(partA[k], cmap=halfGray_halfGreenToRed, vmin=-1., vmax=1.)\n",
    "    ax.set_xticks(range(len(x_values[k])))\n",
    "    ax.set_xticklabels(x_values[k], rotation=-90, fontsize=20)\n",
    "    ax.set_yticks(range(len(y_values[k])))\n",
    "    ax.set_yticklabels(y_values[k], fontsize=20)\n",
    "    ax.tick_params(direction=\"out\")\n",
    "    ax.grid(False)\n",
    "\n",
    "    # label the non-zero entries with their probability in %\n",
    "    for i in range(len(x_values[k])):\n",
    "        for j in range(len(y_values[k])):\n",
    "            if mod_A[i, j] >= 0.:\n",
    "                ax.text(j, i, f\"{partA[k][i,j]*100:.1f}\", ha=\"center\", va=\"center\",\n",
    "                        color=\"white\", fontsize=14)\n",
    "\n",
    "    plt.savefig(f\"transition_matrix{name[k]}.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.savefig(f\"Transition_matrix{name[k]}.svg\", bbox_inches=\"tight\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bf6aa7",
   "metadata": {},
   "source": [
    "## Risk prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e002d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dists={\n",
    "        \"early\": lymph.utils.fast_binomial_pmf(t, max_t, early_p),\n",
    "        \"late\" : lymph.utils.fast_binomial_pmf(t, max_t, mean_late_p)\n",
    "    }\n",
    "\n",
    "layers = [\"V\", \"VII\"]\n",
    "\n",
    "diagnoses_text = [[\"Layer V is negative\", \"Layer V is negative but II positive\"], [\"Layer VII is negative\", \"Layer VII is negative but II & III positive\"]]\n",
    "\n",
    "diagnoses = [[{\"PET\":  np.array([None,None,None,None,0,None])},\n",
    "            {\"PET\": np.array([None,1,None,None,0,None])}],\n",
    "            [{\"PET\": np.array([None,None,None,None,None,0])},\n",
    "            {\"PET\": np.array([None,1,1,None,None,0])}]\n",
    "            ]\n",
    "\n",
    "involvements = [np.array([None,None,None,None,1,None]), np.array([None,None,None,None,None,1])]\n",
    "thin = 50\n",
    "\n",
    "print(\"Probability p for Binomial distribution of late T_stage:\", round(mean_late_p,4))\n",
    "\n",
    "\n",
    "for key in time_dists.keys():\n",
    "    print(\"T_stage = \", key)\n",
    "    for i, layer in enumerate(layers):\n",
    "        for k, diagnose in enumerate(diagnoses[i]):\n",
    "            risk =  extended_systm.risk(\n",
    "                diagnoses=diagnose, inv=involvements[i],\n",
    "                time_dist=time_dists[key], \n",
    "                mode=\"HMM\"\n",
    "            )\n",
    "            print(f\"Risk for Layer {layer} given {diagnoses_text[i][k]}:\", round(risk,4))\n",
    "\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
